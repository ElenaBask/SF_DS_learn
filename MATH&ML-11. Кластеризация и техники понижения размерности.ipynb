{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Метод главных компонент (Principal Component Analysis, PCA)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Проклятие размерности** — это проблема, связанная с экспоненциальным возрастанием объёма данных из-за увеличения размерности пространства."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.decomposition import PCA, TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.matrix([[1,2,3,4],\n",
    "               [5,5,6,7],\n",
    "               [1,4,2,3],\n",
    "               [5,3,2,1],\n",
    "               [8,1,2,2]])\n",
    "\n",
    "df = pd.DataFrame(A,columns  = ['x1','x2','x3','x4'])\n",
    "df_std  = (df - df.mean()) / (df.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        , -0.31622777,  0.04811252, -0.18098843],\n",
       "       [-0.31622777,  1.        ,  0.63900965,  0.61812254],\n",
       "       [ 0.04811252,  0.63900965,  1.        ,  0.94044349],\n",
       "       [-0.18098843,  0.61812254,  0.94044349,  1.        ]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cov_mat = np.cov(df_std.T)\n",
    "cov_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.16195986, -0.52404813, -0.58589647, -0.59654663],\n",
       "       [-0.91705888,  0.20692161, -0.3205394 , -0.11593512]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eigen_val, eigen_vectors = np.linalg.eig(cov_mat)\n",
    "display(eigen_vectors.T[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.        , -0.63245553,  0.        ,  0.26062335],\n",
       "       [ 0.33333333,  1.26491106,  1.73205081,  1.56374007],\n",
       "       [-1.        ,  0.63245553, -0.57735027, -0.1737489 ],\n",
       "       [ 0.33333333,  0.        , -0.57735027, -1.04249338],\n",
       "       [ 1.33333333, -1.26491106, -0.57735027, -0.60812114]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_std.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.16195986, -0.91705888],\n",
       "       [-0.30707099,  0.19616173],\n",
       "       [-0.52404813,  0.20692161],\n",
       "       [-0.81731886,  0.12061043]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eigen_vectors[:2].reshape(4, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.18076349,  0.8244292 ],\n",
       "       [-2.52018312,  0.48944296],\n",
       "       [ 0.08839898,  0.90070028],\n",
       "       [ 1.20859546, -0.55088811],\n",
       "       [ 1.40395217, -1.66368432]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_std.values@(eigen_vectors[:2].reshape(4, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.40033078e-02,  7.55974765e-01],\n",
       "       [ 2.55653399e+00, -7.80431775e-01],\n",
       "       [ 5.14801919e-02,  1.25313470e+00],\n",
       "       [-1.01415002e+00,  2.38808310e-04],\n",
       "       [-1.57986086e+00, -1.22891650e+00]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#определяем метод главных компонент с двумя компонентами\n",
    "pca = PCA(n_components=2)\n",
    "#обучаем алгоритм на наших данных\n",
    "principalComponents = pca.fit_transform(df_std)\n",
    "principalComponents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 5.1**\n",
    "\n",
    "Найдите матрицу ковариаций для векторов $(3, 4, 1)$ и $(1, 6, 2)$ . В качестве ответа укажите сумму всех значений матрицы, округлённую до двух знаков после точки-разделителя."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.33"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = np.array([3, 4, 1])\n",
    "B = np.array([1, 6, 2])\n",
    "np.cov(A, B).sum().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 5.4**\n",
    "\n",
    "Дана матрица признаков\n",
    "\n",
    "Какое минимальное количество главных компонент надо выделить, чтобы сохранить информацию о как минимум 90 % разброса данных?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.matrix([[8,7,2,9],\n",
    "               [1,3,6,3],\n",
    "               [7,2,0,3],\n",
    "               [10,3,1,1],\n",
    "               [8,1,3,4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.61145254,  1.76368007,  0.01320928],\n",
       "       [ 2.08441051,  1.01724955, -0.24417084],\n",
       "       [-0.29568142, -0.95946326, -0.05272576],\n",
       "       [-0.50390826, -1.24373821, -0.50808763],\n",
       "       [ 0.3266317 , -0.57772816,  0.79177495]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(A)\n",
    "df_std  = (df - df.mean()) / (df.std())\n",
    "pca = PCA(n_components=0.9)\n",
    "\n",
    "principalComponents = pca.fit_transform(df_std)\n",
    "principalComponents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Сингулярное разложение (SVD)** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Любую прямоугольную матрицу $A$ размера $(n,m)$ можно представить в виде произведения трёх матриц:\n",
    "\n",
    "$ A = U_{nxn} * D_{nxm} * V^{T}_{mxn} $\n",
    "\n",
    "В этой формуле:\n",
    "\n",
    " $U$ — матрица размера . Все её столбцы ортогональны друг другу и имеют единичную длину. Такие матрицы называются ортогональными. Эта матрица содержит нормированные собственные векторы матрицы\n",
    "\n",
    " $D$ — матрица размера . На её главной диагонали стоят числа, называемые сингулярными числами (они являются корнями из собственных значений матриц  и ), а вне главной диагонали стоят нули. Если мы решаем задачу снижения размерности, то элементы этой матрицы, если их возвести в квадрат, можно интерпретировать как дисперсию, которую объясняет каждая компонента.\n",
    " \n",
    " $V$ — матрица размера . Она тоже ортогональная и содержит нормированные собственные векторы матрицы ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[-1, 1, 0],\n",
    "             [-1, -1, 1]\n",
    "             ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "n_components(5) must be <= n_features(3).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\LENOVO\\Documents\\GitHub\\SF_DS_learn\\MATH&ML-11. Кластеризация и техники понижения размерности.ipynb Ячейка 19\u001b[0m line \u001b[0;36m5\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/LENOVO/Documents/GitHub/SF_DS_learn/MATH%26ML-11.%20%D0%9A%D0%BB%D0%B0%D1%81%D1%82%D0%B5%D1%80%D0%B8%D0%B7%D0%B0%D1%86%D0%B8%D1%8F%20%D0%B8%20%D1%82%D0%B5%D1%85%D0%BD%D0%B8%D0%BA%D0%B8%20%D0%BF%D0%BE%D0%BD%D0%B8%D0%B6%D0%B5%D0%BD%D0%B8%D1%8F%20%D1%80%D0%B0%D0%B7%D0%BC%D0%B5%D1%80%D0%BD%D0%BE%D1%81%D1%82%D0%B8.ipynb#X22sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m svd \u001b[39m=\u001b[39m TruncatedSVD(n_components\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m, n_iter\u001b[39m=\u001b[39m\u001b[39m7\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/LENOVO/Documents/GitHub/SF_DS_learn/MATH%26ML-11.%20%D0%9A%D0%BB%D0%B0%D1%81%D1%82%D0%B5%D1%80%D0%B8%D0%B7%D0%B0%D1%86%D0%B8%D1%8F%20%D0%B8%20%D1%82%D0%B5%D1%85%D0%BD%D0%B8%D0%BA%D0%B8%20%D0%BF%D0%BE%D0%BD%D0%B8%D0%B6%D0%B5%D0%BD%D0%B8%D1%8F%20%D1%80%D0%B0%D0%B7%D0%BC%D0%B5%D1%80%D0%BD%D0%BE%D1%81%D1%82%D0%B8.ipynb#X22sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# обучаем модель на данных X\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/LENOVO/Documents/GitHub/SF_DS_learn/MATH%26ML-11.%20%D0%9A%D0%BB%D0%B0%D1%81%D1%82%D0%B5%D1%80%D0%B8%D0%B7%D0%B0%D1%86%D0%B8%D1%8F%20%D0%B8%20%D1%82%D0%B5%D1%85%D0%BD%D0%B8%D0%BA%D0%B8%20%D0%BF%D0%BE%D0%BD%D0%B8%D0%B6%D0%B5%D0%BD%D0%B8%D1%8F%20%D1%80%D0%B0%D0%B7%D0%BC%D0%B5%D1%80%D0%BD%D0%BE%D1%81%D1%82%D0%B8.ipynb#X22sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m svd\u001b[39m.\u001b[39;49mfit(X)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/LENOVO/Documents/GitHub/SF_DS_learn/MATH%26ML-11.%20%D0%9A%D0%BB%D0%B0%D1%81%D1%82%D0%B5%D1%80%D0%B8%D0%B7%D0%B0%D1%86%D0%B8%D1%8F%20%D0%B8%20%D1%82%D0%B5%D1%85%D0%BD%D0%B8%D0%BA%D0%B8%20%D0%BF%D0%BE%D0%BD%D0%B8%D0%B6%D0%B5%D0%BD%D0%B8%D1%8F%20%D1%80%D0%B0%D0%B7%D0%BC%D0%B5%D1%80%D0%BD%D0%BE%D1%81%D1%82%D0%B8.ipynb#X22sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m# применяем уменьшение размерности к матрице X\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/LENOVO/Documents/GitHub/SF_DS_learn/MATH%26ML-11.%20%D0%9A%D0%BB%D0%B0%D1%81%D1%82%D0%B5%D1%80%D0%B8%D0%B7%D0%B0%D1%86%D0%B8%D1%8F%20%D0%B8%20%D1%82%D0%B5%D1%85%D0%BD%D0%B8%D0%BA%D0%B8%20%D0%BF%D0%BE%D0%BD%D0%B8%D0%B6%D0%B5%D0%BD%D0%B8%D1%8F%20%D1%80%D0%B0%D0%B7%D0%BC%D0%B5%D1%80%D0%BD%D0%BE%D1%81%D1%82%D0%B8.ipynb#X22sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m transformed \u001b[39m=\u001b[39m svd\u001b[39m.\u001b[39mtransform(X)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\decomposition\\_truncated_svd.py:204\u001b[0m, in \u001b[0;36mTruncatedSVD.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    188\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Fit model on training data X.\u001b[39;00m\n\u001b[0;32m    189\u001b[0m \n\u001b[0;32m    190\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    201\u001b[0m \u001b[39m    Returns the transformer object.\u001b[39;00m\n\u001b[0;32m    202\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    203\u001b[0m \u001b[39m# param validation is done in fit_transform\u001b[39;00m\n\u001b[1;32m--> 204\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit_transform(X)\n\u001b[0;32m    205\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[0;32m    139\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m--> 140\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    141\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[0;32m    142\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    143\u001b[0m         \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[0;32m    145\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[0;32m    146\u001b[0m         )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\decomposition\\_truncated_svd.py:237\u001b[0m, in \u001b[0;36mTruncatedSVD.fit_transform\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    235\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39malgorithm \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mrandomized\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    236\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_components \u001b[39m>\u001b[39m X\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]:\n\u001b[1;32m--> 237\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    238\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mn_components(\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_components\u001b[39m}\u001b[39;00m\u001b[39m) must be <=\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    239\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m n_features(\u001b[39m\u001b[39m{\u001b[39;00mX\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m).\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    240\u001b[0m         )\n\u001b[0;32m    241\u001b[0m     U, Sigma, VT \u001b[39m=\u001b[39m randomized_svd(\n\u001b[0;32m    242\u001b[0m         X,\n\u001b[0;32m    243\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_components,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    247\u001b[0m         random_state\u001b[39m=\u001b[39mrandom_state,\n\u001b[0;32m    248\u001b[0m     )\n\u001b[0;32m    250\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcomponents_ \u001b[39m=\u001b[39m VT\n",
      "\u001b[1;31mValueError\u001b[0m: n_components(5) must be <= n_features(3)."
     ]
    }
   ],
   "source": [
    "# создаём объект класса TruncatedSVD\n",
    "# n_components — размерность нового пространства, n_iter — количество итераций\n",
    "svd = TruncatedSVD(n_components=5, n_iter=7, random_state=42)\n",
    "# обучаем модель на данных X\n",
    "svd.fit(X)\n",
    "# применяем уменьшение размерности к матрице X\n",
    "transformed = svd.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Стохастическое вложение соседей с t-распределением (t-SNE)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
