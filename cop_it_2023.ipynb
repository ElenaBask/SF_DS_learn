{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\insps\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import wordnet \n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "\n",
    "import re\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.spatial import distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'C:/Users/insps/Downloads/Telegram Desktop/NLP_tokenized.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_texts</th>\n",
       "      <th>all_comments</th>\n",
       "      <th>all_scores</th>\n",
       "      <th>tokenized_posts</th>\n",
       "      <th>tokenized_comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How many summer Y Combinator fundees decided n...</td>\n",
       "      <td>Going back to school is not identical with giv...</td>\n",
       "      <td>0</td>\n",
       "      <td>['How', 'many', 'summer', 'Y', 'Combinator', '...</td>\n",
       "      <td>['Going', 'back', 'to', 'school', 'is', 'not',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How many summer Y Combinator fundees decided n...</td>\n",
       "      <td>There will invariably be those who don't see t...</td>\n",
       "      <td>1</td>\n",
       "      <td>['How', 'many', 'summer', 'Y', 'Combinator', '...</td>\n",
       "      <td>['There', 'will', 'invariably', 'be', 'those',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How many summer Y Combinator fundees decided n...</td>\n",
       "      <td>For me school is a way to be connected to what...</td>\n",
       "      <td>2</td>\n",
       "      <td>['How', 'many', 'summer', 'Y', 'Combinator', '...</td>\n",
       "      <td>['For', 'me', 'school', 'is', 'a', 'way', 'to'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How many summer Y Combinator fundees decided n...</td>\n",
       "      <td>I guess it really depends on how hungry you ar...</td>\n",
       "      <td>3</td>\n",
       "      <td>['How', 'many', 'summer', 'Y', 'Combinator', '...</td>\n",
       "      <td>['I', 'guess', 'it', 'really', 'depends', 'on'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How many summer Y Combinator fundees decided n...</td>\n",
       "      <td>I know pollground decided to go back to school...</td>\n",
       "      <td>4</td>\n",
       "      <td>['How', 'many', 'summer', 'Y', 'Combinator', '...</td>\n",
       "      <td>['I', 'know', 'pollground', 'decided', 'to', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CBS acquires last.fm for $280m</td>\n",
       "      <td>It will be curious to see where this heads in ...</td>\n",
       "      <td>0</td>\n",
       "      <td>['CBS', 'acquires', 'last.fm', 'for', '$', '28...</td>\n",
       "      <td>['It', 'will', 'be', 'curious', 'to', 'see', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CBS acquires last.fm for $280m</td>\n",
       "      <td>Does this mean that there's now a big-name com...</td>\n",
       "      <td>1</td>\n",
       "      <td>['CBS', 'acquires', 'last.fm', 'for', '$', '28...</td>\n",
       "      <td>['Does', 'this', 'mean', 'that', \"there's\", 'n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CBS acquires last.fm for $280m</td>\n",
       "      <td>Also on BBC News:  http://news.bbc.co.uk/1/low...</td>\n",
       "      <td>2</td>\n",
       "      <td>['CBS', 'acquires', 'last.fm', 'for', '$', '28...</td>\n",
       "      <td>['Also', 'on', 'BBC', 'News', ':', 'http://new...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CBS acquires last.fm for $280m</td>\n",
       "      <td>I don't understand what they do that is worth ...</td>\n",
       "      <td>3</td>\n",
       "      <td>['CBS', 'acquires', 'last.fm', 'for', '$', '28...</td>\n",
       "      <td>['I', \"don't\", 'understand', 'what', 'they', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CBS acquires last.fm for $280m</td>\n",
       "      <td>sold out too cheaply. given their leadership p...</td>\n",
       "      <td>4</td>\n",
       "      <td>['CBS', 'acquires', 'last.fm', 'for', '$', '28...</td>\n",
       "      <td>['sold', 'out', 'too', 'cheaply', '.', 'given'...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          post_texts  \\\n",
       "0  How many summer Y Combinator fundees decided n...   \n",
       "1  How many summer Y Combinator fundees decided n...   \n",
       "2  How many summer Y Combinator fundees decided n...   \n",
       "3  How many summer Y Combinator fundees decided n...   \n",
       "4  How many summer Y Combinator fundees decided n...   \n",
       "5                     CBS acquires last.fm for $280m   \n",
       "6                     CBS acquires last.fm for $280m   \n",
       "7                     CBS acquires last.fm for $280m   \n",
       "8                     CBS acquires last.fm for $280m   \n",
       "9                     CBS acquires last.fm for $280m   \n",
       "\n",
       "                                        all_comments  all_scores  \\\n",
       "0  Going back to school is not identical with giv...           0   \n",
       "1  There will invariably be those who don't see t...           1   \n",
       "2  For me school is a way to be connected to what...           2   \n",
       "3  I guess it really depends on how hungry you ar...           3   \n",
       "4  I know pollground decided to go back to school...           4   \n",
       "5  It will be curious to see where this heads in ...           0   \n",
       "6  Does this mean that there's now a big-name com...           1   \n",
       "7  Also on BBC News:  http://news.bbc.co.uk/1/low...           2   \n",
       "8  I don't understand what they do that is worth ...           3   \n",
       "9  sold out too cheaply. given their leadership p...           4   \n",
       "\n",
       "                                     tokenized_posts  \\\n",
       "0  ['How', 'many', 'summer', 'Y', 'Combinator', '...   \n",
       "1  ['How', 'many', 'summer', 'Y', 'Combinator', '...   \n",
       "2  ['How', 'many', 'summer', 'Y', 'Combinator', '...   \n",
       "3  ['How', 'many', 'summer', 'Y', 'Combinator', '...   \n",
       "4  ['How', 'many', 'summer', 'Y', 'Combinator', '...   \n",
       "5  ['CBS', 'acquires', 'last.fm', 'for', '$', '28...   \n",
       "6  ['CBS', 'acquires', 'last.fm', 'for', '$', '28...   \n",
       "7  ['CBS', 'acquires', 'last.fm', 'for', '$', '28...   \n",
       "8  ['CBS', 'acquires', 'last.fm', 'for', '$', '28...   \n",
       "9  ['CBS', 'acquires', 'last.fm', 'for', '$', '28...   \n",
       "\n",
       "                                  tokenized_comments  \n",
       "0  ['Going', 'back', 'to', 'school', 'is', 'not',...  \n",
       "1  ['There', 'will', 'invariably', 'be', 'those',...  \n",
       "2  ['For', 'me', 'school', 'is', 'a', 'way', 'to'...  \n",
       "3  ['I', 'guess', 'it', 'really', 'depends', 'on'...  \n",
       "4  ['I', 'know', 'pollground', 'decided', 'to', '...  \n",
       "5  ['It', 'will', 'be', 'curious', 'to', 'see', '...  \n",
       "6  ['Does', 'this', 'mean', 'that', \"there's\", 'n...  \n",
       "7  ['Also', 'on', 'BBC', 'News', ':', 'http://new...  \n",
       "8  ['I', \"don't\", 'understand', 'what', 'they', '...  \n",
       "9  ['sold', 'out', 'too', 'cheaply', '.', 'given'...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_texts</th>\n",
       "      <th>all_comments</th>\n",
       "      <th>all_scores</th>\n",
       "      <th>tokenized_posts</th>\n",
       "      <th>tokenized_comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>221360</th>\n",
       "      <td>Gabe Newell Talks Linux Steam Client, Source E...</td>\n",
       "      <td>Even though Steam invites its own problems (it...</td>\n",
       "      <td>0</td>\n",
       "      <td>['Gabe', 'Newell', 'Talks', 'Linux', 'Steam', ...</td>\n",
       "      <td>['Even', 'though', 'Steam', 'invites', 'its', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199502</th>\n",
       "      <td>Dos &amp; Don'ts Upon Taking a New Job</td>\n",
       "      <td>From the guidelines:If the original title begi...</td>\n",
       "      <td>2</td>\n",
       "      <td>['Dos', '&amp;', \"Don'ts\", 'Upon', 'Taking', 'a', ...</td>\n",
       "      <td>['From', 'the', 'guidelines', ':', 'If', 'the'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257622</th>\n",
       "      <td>Lockitron Sells Over 9000 Units in First Week,...</td>\n",
       "      <td>Google cache: http://webcache.googleuserconten...</td>\n",
       "      <td>2</td>\n",
       "      <td>['Lockitron', 'Sells', 'Over', '9000', 'Units'...</td>\n",
       "      <td>['Google', 'cache', ':', 'http://webcache.goog...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286268</th>\n",
       "      <td>Pay Day Loan Rankings: The shady tale of Jooml...</td>\n",
       "      <td>Google cache: http://webcache.googleuserconten...</td>\n",
       "      <td>3</td>\n",
       "      <td>['Pay', 'Day', 'Loan', 'Rankings', ':', 'The',...</td>\n",
       "      <td>['Google', 'cache', ':', 'http://webcache.goog...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297144</th>\n",
       "      <td>How To Get Banned From PyCon</td>\n",
       "      <td>Google cache: http://webcache.googleuserconten...</td>\n",
       "      <td>4</td>\n",
       "      <td>['How', 'To', 'Get', 'Banned', 'From', 'PyCon']</td>\n",
       "      <td>['Google', 'cache', ':', 'http://webcache.goog...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298601</th>\n",
       "      <td>Nasty Gal, an Online Start-Up, Is a Fast-Growi...</td>\n",
       "      <td>Paywall-less Google link to article: http://ww...</td>\n",
       "      <td>1</td>\n",
       "      <td>['Nasty', 'Gal', ',', 'an', 'Online', 'Start-U...</td>\n",
       "      <td>['Paywall-less', 'Google', 'link', 'to', 'arti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355879</th>\n",
       "      <td>DMCA takedown on GPL-copyrighted code</td>\n",
       "      <td>http:&amp;#x2F;&amp;#x2F;webcache.googleusercontent.co...</td>\n",
       "      <td>4</td>\n",
       "      <td>['DMCA', 'takedown', 'on', 'GPL-copyrighted', ...</td>\n",
       "      <td>['http://webcache.googleusercontent.com/search...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379798</th>\n",
       "      <td>Mistakes Programmers Make when Starting in Mac...</td>\n",
       "      <td>http:&amp;#x2F;&amp;#x2F;webcache.googleusercontent.co...</td>\n",
       "      <td>3</td>\n",
       "      <td>['Mistakes', 'Programmers', 'Make', 'when', 'S...</td>\n",
       "      <td>['http://webcache.googleusercontent.com/search...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389267</th>\n",
       "      <td>Web Security Training Platform</td>\n",
       "      <td>http:&amp;#x2F;&amp;#x2F;webcache.googleusercontent.co...</td>\n",
       "      <td>2</td>\n",
       "      <td>['Web', 'Security', 'Training', 'Platform']</td>\n",
       "      <td>['http://webcache.googleusercontent.com/search...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431916</th>\n",
       "      <td>Ask HN: What other sites do you read on a freq...</td>\n",
       "      <td>http:&amp;#x2F;&amp;#x2F;www.reddit.com&amp;#x2F;r&amp;#x2F;pr...</td>\n",
       "      <td>1</td>\n",
       "      <td>['Ask', 'HN', ':', 'What', 'other', 'sites', '...</td>\n",
       "      <td>['http://www.reddit.com/r/programming']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               post_texts  \\\n",
       "221360  Gabe Newell Talks Linux Steam Client, Source E...   \n",
       "199502                 Dos & Don'ts Upon Taking a New Job   \n",
       "257622  Lockitron Sells Over 9000 Units in First Week,...   \n",
       "286268  Pay Day Loan Rankings: The shady tale of Jooml...   \n",
       "297144                       How To Get Banned From PyCon   \n",
       "298601  Nasty Gal, an Online Start-Up, Is a Fast-Growi...   \n",
       "355879              DMCA takedown on GPL-copyrighted code   \n",
       "379798  Mistakes Programmers Make when Starting in Mac...   \n",
       "389267                     Web Security Training Platform   \n",
       "431916  Ask HN: What other sites do you read on a freq...   \n",
       "\n",
       "                                             all_comments  all_scores  \\\n",
       "221360  Even though Steam invites its own problems (it...           0   \n",
       "199502  From the guidelines:If the original title begi...           2   \n",
       "257622  Google cache: http://webcache.googleuserconten...           2   \n",
       "286268  Google cache: http://webcache.googleuserconten...           3   \n",
       "297144  Google cache: http://webcache.googleuserconten...           4   \n",
       "298601  Paywall-less Google link to article: http://ww...           1   \n",
       "355879  http:&#x2F;&#x2F;webcache.googleusercontent.co...           4   \n",
       "379798  http:&#x2F;&#x2F;webcache.googleusercontent.co...           3   \n",
       "389267  http:&#x2F;&#x2F;webcache.googleusercontent.co...           2   \n",
       "431916  http:&#x2F;&#x2F;www.reddit.com&#x2F;r&#x2F;pr...           1   \n",
       "\n",
       "                                          tokenized_posts  \\\n",
       "221360  ['Gabe', 'Newell', 'Talks', 'Linux', 'Steam', ...   \n",
       "199502  ['Dos', '&', \"Don'ts\", 'Upon', 'Taking', 'a', ...   \n",
       "257622  ['Lockitron', 'Sells', 'Over', '9000', 'Units'...   \n",
       "286268  ['Pay', 'Day', 'Loan', 'Rankings', ':', 'The',...   \n",
       "297144    ['How', 'To', 'Get', 'Banned', 'From', 'PyCon']   \n",
       "298601  ['Nasty', 'Gal', ',', 'an', 'Online', 'Start-U...   \n",
       "355879  ['DMCA', 'takedown', 'on', 'GPL-copyrighted', ...   \n",
       "379798  ['Mistakes', 'Programmers', 'Make', 'when', 'S...   \n",
       "389267        ['Web', 'Security', 'Training', 'Platform']   \n",
       "431916  ['Ask', 'HN', ':', 'What', 'other', 'sites', '...   \n",
       "\n",
       "                                       tokenized_comments  \n",
       "221360  ['Even', 'though', 'Steam', 'invites', 'its', ...  \n",
       "199502  ['From', 'the', 'guidelines', ':', 'If', 'the'...  \n",
       "257622  ['Google', 'cache', ':', 'http://webcache.goog...  \n",
       "286268  ['Google', 'cache', ':', 'http://webcache.goog...  \n",
       "297144  ['Google', 'cache', ':', 'http://webcache.goog...  \n",
       "298601  ['Paywall-less', 'Google', 'link', 'to', 'arti...  \n",
       "355879  ['http://webcache.googleusercontent.com/search...  \n",
       "379798  ['http://webcache.googleusercontent.com/search...  \n",
       "389267  ['http://webcache.googleusercontent.com/search...  \n",
       "431916            ['http://www.reddit.com/r/programming']  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data.duplicated('all_comments')].sort_values('all_comments')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I\\'ve started to use Google Docs a lot. Trying Versionate, for text there is little advantage of either. GDocs seem a bit more peppy.I was reading a Paul Graham interview from a while ago:\\nhttp://www.techcrunch.com/2006/09/02/an-interview-with-vc-pa...Here is an interesting quote:\\n\"\\nI wouldn\\'t advise competing with Google in things they\\'re good at. So what is Google good at? As a first approximation, making things their own developers use at work. So they\\'ll do a better job on an online calendar than a video sharing site, for example, because their employees are probably not supposed to be sitting watching videos at work.\\n\"He goes on to mention Google\\'s size, which is probably another factor here.It would be interesting to hear more about what folks at Y-Combinator think about this direct assault on a growing Google service.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data.all_comments.str.find('http') != -1].all_comments.iloc[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "morph = MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_train = data[['post_texts', 'all_comments']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaner(text):\n",
    "    text = re.sub(r'http\\S+', '', text) \n",
    "    text = re.sub('[^a-zA-Z0-9]', ' ', text) \n",
    "    text = word_tokenize(text.lower()) \n",
    "    text = [morph.normal_forms(token)[0] for token in text \n",
    "            if token not in stop_words and len(token) > 2]\n",
    "    text = \" \".join(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\insps\\Documents\\SF\\SF_DS_learn\\cop_it_2023.ipynb Ячейка 11\u001b[0m in \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/insps/Documents/SF/SF_DS_learn/cop_it_2023.ipynb#X24sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m corpus_train_clear \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame()\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/insps/Documents/SF/SF_DS_learn/cop_it_2023.ipynb#X24sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m corpus_train_clear[\u001b[39m'\u001b[39m\u001b[39mpost\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m corpus_train\u001b[39m.\u001b[39;49mpost_texts\u001b[39m.\u001b[39;49mapply(cleaner)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/insps/Documents/SF/SF_DS_learn/cop_it_2023.ipynb#X24sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m corpus_train_clear[\u001b[39m'\u001b[39m\u001b[39mcomments\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m corpus_train\u001b[39m.\u001b[39mall_comments\u001b[39m.\u001b[39mapply(cleaner)\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\pandas\\core\\series.py:4771\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[0;32m   4661\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(\n\u001b[0;32m   4662\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   4663\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4666\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m   4667\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m Series:\n\u001b[0;32m   4668\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   4669\u001b[0m \u001b[39m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4670\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4769\u001b[0m \u001b[39m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4770\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4771\u001b[0m     \u001b[39mreturn\u001b[39;00m SeriesApply(\u001b[39mself\u001b[39;49m, func, convert_dtype, args, kwargs)\u001b[39m.\u001b[39;49mapply()\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\pandas\\core\\apply.py:1105\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1102\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_str()\n\u001b[0;32m   1104\u001b[0m \u001b[39m# self.f is Callable\u001b[39;00m\n\u001b[1;32m-> 1105\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\pandas\\core\\apply.py:1156\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1154\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1155\u001b[0m         values \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39mastype(\u001b[39mobject\u001b[39m)\u001b[39m.\u001b[39m_values\n\u001b[1;32m-> 1156\u001b[0m         mapped \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39;49mmap_infer(\n\u001b[0;32m   1157\u001b[0m             values,\n\u001b[0;32m   1158\u001b[0m             f,\n\u001b[0;32m   1159\u001b[0m             convert\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconvert_dtype,\n\u001b[0;32m   1160\u001b[0m         )\n\u001b[0;32m   1162\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(mapped) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(mapped[\u001b[39m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1163\u001b[0m     \u001b[39m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1164\u001b[0m     \u001b[39m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1165\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\u001b[39m.\u001b[39m_constructor_expanddim(\u001b[39mlist\u001b[39m(mapped), index\u001b[39m=\u001b[39mobj\u001b[39m.\u001b[39mindex)\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\pandas\\_libs\\lib.pyx:2918\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\insps\\Documents\\SF\\SF_DS_learn\\cop_it_2023.ipynb Ячейка 11\u001b[0m in \u001b[0;36m5\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/insps/Documents/SF/SF_DS_learn/cop_it_2023.ipynb#X24sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m text \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39msub(\u001b[39m'\u001b[39m\u001b[39m[^a-zA-Z0-9]\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m, text) \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/insps/Documents/SF/SF_DS_learn/cop_it_2023.ipynb#X24sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m text \u001b[39m=\u001b[39m word_tokenize(text\u001b[39m.\u001b[39mlower()) \n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/insps/Documents/SF/SF_DS_learn/cop_it_2023.ipynb#X24sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m text \u001b[39m=\u001b[39m [morph\u001b[39m.\u001b[39mnormal_forms(token)[\u001b[39m0\u001b[39m] \u001b[39mfor\u001b[39;00m token \u001b[39min\u001b[39;00m text \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/insps/Documents/SF/SF_DS_learn/cop_it_2023.ipynb#X24sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m         \u001b[39mif\u001b[39;00m token \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m stop_words \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(token) \u001b[39m>\u001b[39m \u001b[39m2\u001b[39m]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/insps/Documents/SF/SF_DS_learn/cop_it_2023.ipynb#X24sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m text \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(text)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/insps/Documents/SF/SF_DS_learn/cop_it_2023.ipynb#X24sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mreturn\u001b[39;00m text\n",
      "\u001b[1;32mc:\\Users\\insps\\Documents\\SF\\SF_DS_learn\\cop_it_2023.ipynb Ячейка 11\u001b[0m in \u001b[0;36m5\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/insps/Documents/SF/SF_DS_learn/cop_it_2023.ipynb#X24sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m text \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39msub(\u001b[39m'\u001b[39m\u001b[39m[^a-zA-Z0-9]\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m, text) \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/insps/Documents/SF/SF_DS_learn/cop_it_2023.ipynb#X24sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m text \u001b[39m=\u001b[39m word_tokenize(text\u001b[39m.\u001b[39mlower()) \n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/insps/Documents/SF/SF_DS_learn/cop_it_2023.ipynb#X24sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m text \u001b[39m=\u001b[39m [morph\u001b[39m.\u001b[39;49mnormal_forms(token)[\u001b[39m0\u001b[39m] \u001b[39mfor\u001b[39;00m token \u001b[39min\u001b[39;00m text \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/insps/Documents/SF/SF_DS_learn/cop_it_2023.ipynb#X24sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m         \u001b[39mif\u001b[39;00m token \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m stop_words \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(token) \u001b[39m>\u001b[39m \u001b[39m2\u001b[39m]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/insps/Documents/SF/SF_DS_learn/cop_it_2023.ipynb#X24sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m text \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(text)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/insps/Documents/SF/SF_DS_learn/cop_it_2023.ipynb#X24sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mreturn\u001b[39;00m text\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\pymorphy2\\analyzer.py:350\u001b[0m, in \u001b[0;36mMorphAnalyzer.normal_forms\u001b[1;34m(self, word)\u001b[0m\n\u001b[0;32m    347\u001b[0m seen \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m()\n\u001b[0;32m    348\u001b[0m result \u001b[39m=\u001b[39m []\n\u001b[1;32m--> 350\u001b[0m \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparse(word):\n\u001b[0;32m    351\u001b[0m     normal_form \u001b[39m=\u001b[39m p[\u001b[39m2\u001b[39m]\n\u001b[0;32m    352\u001b[0m     \u001b[39mif\u001b[39;00m normal_form \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m seen:\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\pymorphy2\\analyzer.py:315\u001b[0m, in \u001b[0;36mMorphAnalyzer.parse\u001b[1;34m(self, word)\u001b[0m\n\u001b[0;32m    312\u001b[0m word_lower \u001b[39m=\u001b[39m word\u001b[39m.\u001b[39mlower()\n\u001b[0;32m    314\u001b[0m \u001b[39mfor\u001b[39;00m analyzer, is_terminal \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_units:\n\u001b[1;32m--> 315\u001b[0m     res\u001b[39m.\u001b[39;49mextend(analyzer\u001b[39m.\u001b[39;49mparse(word, word_lower, seen))\n\u001b[0;32m    317\u001b[0m     \u001b[39mif\u001b[39;00m is_terminal \u001b[39mand\u001b[39;00m res:\n\u001b[0;32m    318\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "corpus_train_clear = pd.DataFrame()\n",
    "corpus_train_clear['post'] = corpus_train.post_texts.apply(cleaner)\n",
    "corpus_train_clear['comments'] = corpus_train.all_comments.apply(cleaner)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_train_clear['score'] = data.all_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_cl = 'C:/Users/insps/Downloads/Telegram Desktop/NLP_cleared.csv'\n",
    "corpus_train_clear = pd.read_csv(file_cl)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post</th>\n",
       "      <th>comments</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>many summer combinator fundees decided continu...</td>\n",
       "      <td>going back school identical giving founders ba...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>many summer combinator fundees decided continu...</td>\n",
       "      <td>invariably see success set fall back original ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>many summer combinator fundees decided continu...</td>\n",
       "      <td>school way connected going real world entered ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>many summer combinator fundees decided continu...</td>\n",
       "      <td>guess really depends hungry much believe produ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>many summer combinator fundees decided continu...</td>\n",
       "      <td>know pollground decided back school getting co...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>cbs acquires last 280m</td>\n",
       "      <td>curious see heads long run cbs tear fit image ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>cbs acquires last 280m</td>\n",
       "      <td>mean big name company fight repeal recent stre...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>cbs acquires last 280m</td>\n",
       "      <td>also bbc news nice see london based hit headlines</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>cbs acquires last 280m</td>\n",
       "      <td>understand worth 70m year</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>cbs acquires last 280m</td>\n",
       "      <td>sold cheaply given leadership position ask lea...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                post  \\\n",
       "0  many summer combinator fundees decided continu...   \n",
       "1  many summer combinator fundees decided continu...   \n",
       "2  many summer combinator fundees decided continu...   \n",
       "3  many summer combinator fundees decided continu...   \n",
       "4  many summer combinator fundees decided continu...   \n",
       "5                             cbs acquires last 280m   \n",
       "6                             cbs acquires last 280m   \n",
       "7                             cbs acquires last 280m   \n",
       "8                             cbs acquires last 280m   \n",
       "9                             cbs acquires last 280m   \n",
       "\n",
       "                                            comments  score  \n",
       "0  going back school identical giving founders ba...      0  \n",
       "1  invariably see success set fall back original ...      1  \n",
       "2  school way connected going real world entered ...      2  \n",
       "3  guess really depends hungry much believe produ...      3  \n",
       "4  know pollground decided back school getting co...      4  \n",
       "5  curious see heads long run cbs tear fit image ...      0  \n",
       "6  mean big name company fight repeal recent stre...      1  \n",
       "7  also bbc news nice see london based hit headlines      2  \n",
       "8                          understand worth 70m year      3  \n",
       "9  sold cheaply given leadership position ask lea...      4  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_train_clear.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_train_clear.to_csv('NLP_cleared.csv', index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 440535 entries, 0 to 440534\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count   Dtype \n",
      "---  ------    --------------   ----- \n",
      " 0   post      440135 non-null  object\n",
      " 1   comments  439139 non-null  object\n",
      " 2   score     440535 non-null  int64 \n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 10.1+ MB\n"
     ]
    }
   ],
   "source": [
    "corpus_train_clear.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_and_posts_cleared = corpus_train_clear.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer()\n",
    "matrix_post = count_vect.fit_transform(comments_and_posts_cleared.post.astype('U'))\n",
    "matrix_comments = count_vect.transform(comments_and_posts_cleared.comments.astype('U'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "220072"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(count_vect.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(440535, 220072)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_comments.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vect = TfidfVectorizer(min_df=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'count_vect' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\insps\\Documents\\SF\\SF_DS_learn\\cop_it_2023.ipynb Ячейка 21\u001b[0m in \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/insps/Documents/SF/SF_DS_learn/cop_it_2023.ipynb#X43sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m matrix_post_ti \u001b[39m=\u001b[39m count_vect\u001b[39m.\u001b[39mfit_transform(comments_and_posts_cleared\u001b[39m.\u001b[39mpost)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/insps/Documents/SF/SF_DS_learn/cop_it_2023.ipynb#X43sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m matrix_comments_ti \u001b[39m=\u001b[39m count_vect\u001b[39m.\u001b[39mtransform(comments_and_posts_cleared\u001b[39m.\u001b[39mcomments)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'count_vect' is not defined"
     ]
    }
   ],
   "source": [
    "matrix_post_ti = count_vect.fit_transform(comments_and_posts_cleared.post)\n",
    "matrix_comments_ti = count_vect.transform(comments_and_posts_cleared.comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(440535, 220072)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_comments_ti.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x220072 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 62 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_comments[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Incompatible dimension for X and Y matrices: X.shape[1] == 35357 while Y.shape[1] == 220072",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\insps\\Documents\\SF\\SF_DS_learn\\cop_it_2023.ipynb Ячейка 25\u001b[0m in \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/insps/Documents/SF/SF_DS_learn/cop_it_2023.ipynb#X45sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpairwise\u001b[39;00m \u001b[39mimport\u001b[39;00m cosine_similarity\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/insps/Documents/SF/SF_DS_learn/cop_it_2023.ipynb#X45sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m5\u001b[39m):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/insps/Documents/SF/SF_DS_learn/cop_it_2023.ipynb#X45sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     \u001b[39mprint\u001b[39m(cosine_similarity(matrix_post[\u001b[39m0\u001b[39;49m], matrix_comments[i]))\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:1393\u001b[0m, in \u001b[0;36mcosine_similarity\u001b[1;34m(X, Y, dense_output)\u001b[0m\n\u001b[0;32m   1358\u001b[0m \u001b[39m\"\"\"Compute cosine similarity between samples in X and Y.\u001b[39;00m\n\u001b[0;32m   1359\u001b[0m \n\u001b[0;32m   1360\u001b[0m \u001b[39mCosine similarity, or the cosine kernel, computes similarity as the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1389\u001b[0m \u001b[39m    Returns the cosine similarity between samples in X and Y.\u001b[39;00m\n\u001b[0;32m   1390\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1391\u001b[0m \u001b[39m# to avoid recursive import\u001b[39;00m\n\u001b[1;32m-> 1393\u001b[0m X, Y \u001b[39m=\u001b[39m check_pairwise_arrays(X, Y)\n\u001b[0;32m   1395\u001b[0m X_normalized \u001b[39m=\u001b[39m normalize(X, copy\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m   1396\u001b[0m \u001b[39mif\u001b[39;00m X \u001b[39mis\u001b[39;00m Y:\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:180\u001b[0m, in \u001b[0;36mcheck_pairwise_arrays\u001b[1;34m(X, Y, precomputed, dtype, accept_sparse, force_all_finite, copy)\u001b[0m\n\u001b[0;32m    174\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    175\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mPrecomputed metric requires shape \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    176\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m(n_queries, n_indexed). Got (\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m) \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    177\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mfor \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m indexed.\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (X\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], X\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m], Y\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m])\n\u001b[0;32m    178\u001b[0m         )\n\u001b[0;32m    179\u001b[0m \u001b[39melif\u001b[39;00m X\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m] \u001b[39m!=\u001b[39m Y\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]:\n\u001b[1;32m--> 180\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    181\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mIncompatible dimension for X and Y matrices: \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    182\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mX.shape[1] == \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m while Y.shape[1] == \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (X\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m], Y\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m])\n\u001b[0;32m    183\u001b[0m     )\n\u001b[0;32m    185\u001b[0m \u001b[39mreturn\u001b[39;00m X, Y\n",
      "\u001b[1;31mValueError\u001b[0m: Incompatible dimension for X and Y matrices: X.shape[1] == 35357 while Y.shape[1] == 220072"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "for i in range(5):\n",
    "    print(cosine_similarity(matrix_post[0], matrix_comments[i]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
