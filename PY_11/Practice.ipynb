{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   cust_id  cust_sale  cust_year_birth  cust_order\n",
      "0      128       0.00             2008        1400\n",
      "1     1201       0.00             2000       14142\n",
      "2     9832       0.20             2002         900\n",
      "3     4392       0.15             2000        1240\n",
      "4     7472       0.30             1961        8430\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def delete_columns(df, col=[]):\n",
    "    \"\"\"\n",
    "    Напишите функцию delete_columns(df, col=[]), которая удаляет столбцы из DataFrame и возвращает новую таблицу. \n",
    "    Если одного из указанных столбцов в таблице не существует, то функция должна возвращать None.\n",
    "    \"\"\"\n",
    "    for i in col:\n",
    "        if i not in df.columns:\n",
    "            return\n",
    "    return df.drop(col, axis=1)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    customer_df = pd.DataFrame({\n",
    "        'number': [0, 1, 2, 3, 4],\n",
    "        'cust_id': [128, 1201, 9832, 4392, 7472],\n",
    "        'cust_age': [13, 21, 19, 21, 60],\n",
    "        'cust_sale': [0, 0, 0.2, 0.15, 0.3],\n",
    "        'cust_year_birth': [2008, 2000, 2002, 2000, 1961],\n",
    "        'cust_order': [1400, 14142, 900, 1240, 8430]\n",
    "    })\n",
    "    \n",
    "    columns_for_delete= ['number', 'cust_age'] #выбранные вами столбцы\n",
    "    new_df = delete_columns(customer_df, columns_for_delete)\n",
    "    print(new_df)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84.93"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Для каждой страны рассчитайте плотность населения (количество человек на квадратный километр).\n",
    "Затем по полученным данным рассчитайте среднее по плотностям населения в указанных странах. Ответ округлите до сотых.\n",
    "\"\"\"\n",
    "countries_df = pd.DataFrame({\n",
    "    'country': ['Англия', 'Канада', 'США', 'Россия', 'Украина', 'Беларусь', 'Казахстан'],\n",
    "    'population': [56.29, 38.05, 322.28, 146.24, 45.5, 9.5, 17.04],\n",
    "    'square': [133396, 9984670, 9826630, 17125191, 603628, 207600, 2724902]\n",
    "})\n",
    "\n",
    "countries_df['pop_density'] = countries_df['population']*1000000/countries_df['square']\n",
    "round(countries_df['pop_density'].mean(), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>Colors Reported</th>\n",
       "      <th>Shape Reported</th>\n",
       "      <th>State</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ithaca</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TRIANGLE</td>\n",
       "      <td>NY</td>\n",
       "      <td>6/1/1930 22:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Willingboro</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>NJ</td>\n",
       "      <td>6/30/1930 20:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Holyoke</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OVAL</td>\n",
       "      <td>CO</td>\n",
       "      <td>2/15/1931 14:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Abilene</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DISK</td>\n",
       "      <td>KS</td>\n",
       "      <td>6/1/1931 13:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>New York Worlds Fair</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LIGHT</td>\n",
       "      <td>NY</td>\n",
       "      <td>4/18/1933 19:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18236</th>\n",
       "      <td>Grant Park</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TRIANGLE</td>\n",
       "      <td>IL</td>\n",
       "      <td>12/31/2000 23:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18237</th>\n",
       "      <td>Spirit Lake</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DISK</td>\n",
       "      <td>IA</td>\n",
       "      <td>12/31/2000 23:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18238</th>\n",
       "      <td>Eagle River</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WI</td>\n",
       "      <td>12/31/2000 23:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18239</th>\n",
       "      <td>Eagle River</td>\n",
       "      <td>RED</td>\n",
       "      <td>LIGHT</td>\n",
       "      <td>WI</td>\n",
       "      <td>12/31/2000 23:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18240</th>\n",
       "      <td>Ybor</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OVAL</td>\n",
       "      <td>FL</td>\n",
       "      <td>12/31/2000 23:59</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18241 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       City Colors Reported Shape Reported State  \\\n",
       "0                    Ithaca             NaN       TRIANGLE    NY   \n",
       "1               Willingboro             NaN          OTHER    NJ   \n",
       "2                   Holyoke             NaN           OVAL    CO   \n",
       "3                   Abilene             NaN           DISK    KS   \n",
       "4      New York Worlds Fair             NaN          LIGHT    NY   \n",
       "...                     ...             ...            ...   ...   \n",
       "18236            Grant Park             NaN       TRIANGLE    IL   \n",
       "18237           Spirit Lake             NaN           DISK    IA   \n",
       "18238           Eagle River             NaN            NaN    WI   \n",
       "18239           Eagle River             RED          LIGHT    WI   \n",
       "18240                  Ybor             NaN           OVAL    FL   \n",
       "\n",
       "                   Time  \n",
       "0        6/1/1930 22:00  \n",
       "1       6/30/1930 20:00  \n",
       "2       2/15/1931 14:00  \n",
       "3        6/1/1931 13:00  \n",
       "4       4/18/1933 19:00  \n",
       "...                 ...  \n",
       "18236  12/31/2000 23:00  \n",
       "18237  12/31/2000 23:00  \n",
       "18238  12/31/2000 23:45  \n",
       "18239  12/31/2000 23:45  \n",
       "18240  12/31/2000 23:59  \n",
       "\n",
       "[18241 rows x 5 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report_ufo = pd.read_csv('https://raw.githubusercontent.com/justmarkham/pandas-videos/master/data/ufo.csv')\n",
    "report_ufo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1999\n",
       "Name: Time, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# В каком году отмечается наибольшее количество случаев наблюдения НЛО в США?\n",
    "report_ufo['Time'] = pd.to_datetime(report_ufo['Time'], dayfirst=True)\n",
    "report_ufo['Time'].dt.year.mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Найдите средний интервал времени (в днях) между двумя последовательными\n",
    "# случаями наблюдения НЛО в штате Невада (NV)\n",
    "report_ufo['Date'] = report_ufo['Time'].dt.date\n",
    "round(report_ufo[report_ufo['State'] == 'NV']['Date'].diff().dt.days.mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
